# Governance

This section covers policies, risks, ethics, and compliance for AI usage. Even if you're eager to start building, understanding these guardrails prevents costly mistakes and ensures responsible AI adoption.

## Topics

| File | Description |
|------|-------------|
| [Orientation](./orientation.md) | What AI changes in engineering, failure modes, and policy basics |
| [Bias, Harms, and Transparency](./bias-harms-transparency.md) | Recognizing harmful outputs and setting appropriate user expectations |
| [Operational Guardrails](./operational-guardrails.md) | Data classification, secrets handling, and when to avoid AI |
| [Evals Basics](./evals-basics.md) | Defining success, building eval sets, and human review gates |
| [Legal, IP, and Compliance](./legal-ip-compliance.md) | Provider terms, copyright, attribution, and data residency |

## Prerequisites

Familiarity with [Core Concepts](../01-core-concepts/README.md) helps but isn't required.

## Reading Order

1. **Orientation** — Start here for the big picture
2. **Bias, Harms, and Transparency** — Critical for any user-facing AI
3. **Operational Guardrails** — Daily decision-making framework
4. **Evals Basics** — How to measure if AI is working
5. **Legal, IP, and Compliance** — Know the boundaries
